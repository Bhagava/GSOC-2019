{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv2D, SeparableConv2D, Conv2DTranspose\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Reshape\nfrom tensorflow.keras.layers import Permute\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Concatenate\nfrom tensorflow.keras.layers import Lambda\nfrom tensorflow.keras.models import Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pre-process images\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\n\ntrain_path = '../input/wnet-data-large/data_large/Data_Large/train/'\nval_path = '../input/wnetdataset/data/Data/val/'\n\ntrain_images = os.listdir(train_path)\nval_images = os.listdir(val_path)\n\nX_train = []\nX_val = []\n\nfor i in range(len(train_images)):\n    img = cv2.imread(train_path+train_images[i])\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    resized = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA)\n    X_train.append(resized)\nX_train = np.asarray(X_train)\nX_train = X_train.astype('float32')/255.\nX_train = np.reshape(X_train, (len(X_train), 224, 224, 1))\n\nfor i in range(len(val_images)):\n    img = cv2.imread(val_path+val_images[i])\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    resized = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA)\n    X_val.append(resized)\nX_val = np.asarray(X_val)\nX_val = X_val.astype('float32')/255.\nX_val = np.reshape(X_val, (len(X_val), 224, 224, 1))\n\nprint(\"Number of train images:\",len(X_train), \"Shape of X_train:\", X_train.shape)\nprint(\"Number of val images:\",len(X_val), \"Shape of X_val:\", X_val.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shuffle X_train and X_val\nnp.random.shuffle(X_train)\nnp.random.shuffle(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Parameters\ninput_img = Input(shape=(224, 224, 1))\ndroprate=0.2\ndroprate_input = 0.8\nnum_classes = 3 #background, cell boundary, cell.\nnum_epochs = 10\nae_lr = 0.001\nenc_lr = 0.0001\nnum_batches = 80\nbatch_size = len(X_train)//num_batches\nbatch_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Concatination fro skip connections in the network\ndef upconv_concat(bottom_a, bottom_b, n_filter, pool_size, stride, padding='VALID'):\n    up_conv = Conv2DTranspose(filters=n_filter, kernel_size=[pool_size, pool_size],\n                                         strides=stride, padding=padding)(bottom_a)\n    return Concatenate(axis=-1)([up_conv, bottom_b])\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Encoder\n\n#Module 1\nconv_1_1 = Conv2D(filters = 64, kernel_size = 3, activation='relu', padding='same')(input_img)\nconv_1_1_bn = BatchNormalization()(conv_1_1)\nconv_1_1_do = Dropout(droprate)(conv_1_1_bn)\n\nconv_1_2 = Conv2D(filters = 64, kernel_size = 3, activation='relu', padding='same')(conv_1_1_do)\nconv_1_2_bn = BatchNormalization()(conv_1_2)\nconv_1_2_do = Dropout(droprate)(conv_1_2_bn)\n\npool_1 = MaxPooling2D(pool_size= 2, strides = 2)(conv_1_2_do) #Module 1 to Module 2\n\n#Module 2\n\nconv_2_1 = SeparableConv2D(filters = 128, kernel_size = 3, activation='relu', padding='same')(pool_1)\nconv_2_1_bn = BatchNormalization()(conv_2_1)\nconv_2_1_do = Dropout(droprate)(conv_2_1_bn)\n\nconv_2_2 = SeparableConv2D(filters = 128, kernel_size = 3, activation='relu', padding='same')(conv_2_1_do)\nconv_2_2_bn = BatchNormalization()(conv_2_2)\nconv_2_2_do = Dropout(droprate)(conv_2_2_bn)\n\npool_2 = MaxPooling2D(pool_size= 2, strides = 2)(conv_2_2_do) #Module 2 to Module 3\n\n#Module 3\n\nconv_3_1 = SeparableConv2D(filters = 256, kernel_size = 3, activation='relu', padding='same')(pool_2)\nconv_3_1_bn = BatchNormalization()(conv_3_1)\nconv_3_1_do = Dropout(droprate)(conv_3_1_bn)\n\nconv_3_2 = SeparableConv2D(filters = 256, kernel_size = 3, activation='relu', padding='same')(conv_3_1_do)\nconv_3_2_bn = BatchNormalization()(conv_3_2)\nconv_3_2_do = Dropout(droprate)(conv_3_2_bn)\n\npool_3 = MaxPooling2D(pool_size= 2, strides = 2)(conv_3_2_do) #Module 3 to Module 4\n\n#Module 4\n\nconv_4_1 = SeparableConv2D(filters = 512, kernel_size = 3, activation='relu', padding='same')(pool_3)\nconv_4_1_bn = BatchNormalization()(conv_4_1)\nconv_4_1_do = Dropout(droprate)(conv_4_1_bn)\n\nconv_4_2 = SeparableConv2D(filters = 512, kernel_size = 3, activation='relu', padding='same')(conv_4_1_do)\nconv_4_2_bn = BatchNormalization()(conv_4_2)\nconv_4_2_do = Dropout(droprate)(conv_4_2_bn)\n\npool_4 = MaxPooling2D(pool_size= 2, strides = 2)(conv_4_2_do) #Module 4 to Module 5\n\n#Module 5\n\nconv_5_1 = SeparableConv2D(filters = 1024, kernel_size = 3, activation='relu', padding='same')(pool_4)\nconv_5_1_bn = BatchNormalization()(conv_5_1)\nconv_5_1_do = Dropout(droprate)(conv_5_1_bn)\n\nconv_5_2 = SeparableConv2D(filters = 1024, kernel_size = 3, activation='relu', padding='same')(conv_5_1_do)\nconv_5_2_bn = BatchNormalization()(conv_5_2)\nconv_5_2_do = Dropout(droprate)(conv_5_2_bn)\n\nupconv_1 = upconv_concat(conv_5_2_do, conv_4_2_do, n_filter=512, pool_size=2, stride=2) #Module 5 to 6\n\n#Module 6\n\nconv_6_1 = SeparableConv2D(filters = 512, kernel_size = 3, activation='relu', padding='same')(upconv_1)\nconv_6_1_bn = BatchNormalization()(conv_6_1)\nconv_6_1_do = Dropout(droprate)(conv_6_1_bn)\n\nconv_6_2 = SeparableConv2D(filters = 512, kernel_size = 3, activation='relu', padding='same')(conv_6_1_do)\nconv_6_2_bn = BatchNormalization()(conv_6_2)\nconv_6_2_do = Dropout(droprate)(conv_6_2_bn)\n\nupconv_2 = upconv_concat(conv_6_2_do, conv_3_2_do, n_filter=256, pool_size=2, stride=2) #Module 6 to 7\n\n#Module 7\n\nconv_7_1 = SeparableConv2D(filters = 256, kernel_size = 3, activation='relu', padding='same')(upconv_2)\nconv_7_1_bn = BatchNormalization()(conv_7_1)\nconv_7_1_do = Dropout(droprate)(conv_7_1_bn)\n\nconv_7_2 = SeparableConv2D(filters = 256, kernel_size = 3, activation='relu', padding='same')(conv_7_1_do)\nconv_7_2_bn = BatchNormalization()(conv_7_2)\nconv_7_2_do = Dropout(droprate)(conv_7_2_bn)\n\nupconv_3 = upconv_concat(conv_7_2_do, conv_2_2_do, n_filter=128, pool_size=2, stride=2) #Module 7 to 8\n\n#Module 8\n\nconv_8_1 = SeparableConv2D(filters = 128, kernel_size = 3, activation='relu', padding='same')(upconv_3)\nconv_8_1_bn = BatchNormalization()(conv_8_1)\nconv_8_1_do = Dropout(droprate)(conv_8_1_bn)\n\nconv_8_2 = SeparableConv2D(filters = 128, kernel_size = 3, activation='relu', padding='same')(conv_8_1_do)\nconv_8_2_bn = BatchNormalization()(conv_8_2)\nconv_8_2_do = Dropout(droprate)(conv_8_2_bn)\n\nupconv_4 = upconv_concat(conv_8_2_do, conv_1_2_do, n_filter=64, pool_size=2, stride=2) #Module 8 to 9\n\n#Module 9\n\nconv_9_1 = SeparableConv2D(filters = 64, kernel_size = 3, activation='relu', padding='same')(upconv_4)\nconv_9_1_bn = BatchNormalization()(conv_9_1)\nconv_9_1_do = Dropout(droprate)(conv_9_1_bn)\n\nconv_9_2 = SeparableConv2D(filters = 64, kernel_size = 3, activation='relu', padding='same')(conv_9_1_do)\nconv_9_2_bn = BatchNormalization()(conv_9_2)\nconv_9_2_do = Dropout(droprate)(conv_9_2_bn)\n\n# encoder_output = Custom_Conv()(conv_9_2_do, k_size=1, num_outputs=3, stride=1) \n\nfinal_conv = Conv2D(num_classes, 1, 1)(conv_9_2_do)\n\nx = Reshape((num_classes, 224*224))(final_conv)\nx = Permute((2,1))(x)\nx = Activation(\"softmax\")(x)\nencoder_output = Reshape((224, 224, num_classes))(x) #Module 9 to 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decoder\n\n#Module 10\n\nconv_10_1 = Conv2D(filters = 64, kernel_size = 3, activation='relu', padding='same')(encoder_output)\nconv_10_1_bn = BatchNormalization()(conv_10_1)\nconv_10_1_do = Dropout(droprate)(conv_10_1_bn)\n\nconv_10_2 = Conv2D(filters = 64, kernel_size = 3, activation='relu', padding='same')(conv_10_1_do)\nconv_10_2_bn = BatchNormalization()(conv_10_2)\nconv_10_2_do = Dropout(droprate)(conv_10_2_bn)\n\npool_5 = MaxPooling2D(pool_size= 2, strides = 2)(conv_10_2_do) #Module 10 to 11\n\n#Module 11\n\nconv_11_1 = SeparableConv2D(filters = 128, kernel_size = 3, activation='relu', padding='same')(pool_5)\nconv_11_1_bn = BatchNormalization()(conv_11_1)\nconv_11_1_do = Dropout(droprate)(conv_11_1_bn)\n\nconv_11_2 = SeparableConv2D(filters = 128, kernel_size = 3, activation='relu', padding='same')(conv_11_1_do)\nconv_11_2_bn = BatchNormalization()(conv_11_2)\nconv_11_2_do = Dropout(droprate)(conv_11_2_bn)\n\npool_6 = MaxPooling2D(pool_size= 2, strides = 2)(conv_11_2_do) #Module 11 to 12\n\n#Module 12\n\nconv_12_1 = SeparableConv2D(filters = 256, kernel_size = 3, activation='relu', padding='same')(pool_6)\nconv_12_1_bn = BatchNormalization()(conv_12_1)\nconv_12_1_do = Dropout(droprate)(conv_12_1_bn)\n\nconv_12_2 = SeparableConv2D(filters = 256, kernel_size = 3, activation='relu', padding='same')(conv_12_1_do)\nconv_12_2_bn = BatchNormalization()(conv_12_2)\nconv_12_2_do = Dropout(droprate)(conv_12_2_bn)\n\npool_7 = MaxPooling2D(pool_size= 2, strides = 2)(conv_12_2_do) #Module 12 to 13\n\n#Module 13\n\nconv_13_1 = SeparableConv2D(filters = 512, kernel_size = 3, activation='relu', padding='same')(pool_7)\nconv_13_1_bn = BatchNormalization()(conv_13_1)\nconv_13_1_do = Dropout(droprate)(conv_13_1_bn)\n\nconv_13_2 = SeparableConv2D(filters = 512, kernel_size = 3, activation='relu', padding='same')(conv_13_1_do)\nconv_13_2_bn = BatchNormalization()(conv_13_2)\nconv_13_2_do = Dropout(droprate)(conv_13_2_bn)\n\npool_8 = MaxPooling2D(pool_size= 2, strides = 2)(conv_13_2_do) #Module 13 to 14\n\n#Module 14\n\nconv_14_1 = SeparableConv2D(filters = 1024, kernel_size = 3, activation='relu', padding='same')(pool_8)\nconv_14_1_bn = BatchNormalization()(conv_14_1)\nconv_14_1_do = Dropout(droprate)(conv_14_1_bn)\n\nconv_14_2 = SeparableConv2D(filters = 1024, kernel_size = 3, activation='relu', padding='same')(conv_14_1_do)\nconv_14_2_bn = BatchNormalization()(conv_14_2)\nconv_14_2_do = Dropout(droprate)(conv_14_2_bn)\n\nupconv_5 = upconv_concat(conv_14_2_do, conv_13_2_do, n_filter=512, pool_size=2, stride=2)  #Module 14 to 15\n\n#Module 15\n\nconv_15_1 = SeparableConv2D(filters = 512, kernel_size = 3, activation='relu', padding='same')(upconv_5)\nconv_15_1_bn = BatchNormalization()(conv_15_1)\nconv_15_1_do = Dropout(droprate)(conv_15_1_bn)\n\nconv_15_2 = SeparableConv2D(filters = 512, kernel_size = 3, activation='relu', padding='same')(conv_15_1_do)\nconv_15_2_bn = BatchNormalization()(conv_15_2)\nconv_15_2_do = Dropout(droprate)(conv_15_2_bn)\n\nupconv_6 = upconv_concat(conv_15_2_do, conv_12_2_do, n_filter=256, pool_size=2, stride=2)  #Module 15 to 16\n\n#Module 16\n\nconv_16_1 = SeparableConv2D(filters = 256, kernel_size = 3, activation='relu', padding='same')(upconv_6)\nconv_16_1_bn = BatchNormalization()(conv_16_1)\nconv_16_1_do = Dropout(droprate)(conv_16_1_bn)\n\nconv_16_2 = SeparableConv2D(filters = 256, kernel_size = 3, activation='relu', padding='same')(conv_16_1_do)\nconv_16_2_bn = BatchNormalization()(conv_16_2)\nconv_16_2_do = Dropout(droprate)(conv_16_2_bn)\n\nupconv_7 = upconv_concat(conv_16_2_do, conv_11_2_do, n_filter=128, pool_size=2, stride=2)  #Module 16 to 17\n\n#Module 17\n\nconv_17_1 = SeparableConv2D(filters = 128, kernel_size = 3, activation='relu', padding='same')(upconv_7)\nconv_17_1_bn = BatchNormalization()(conv_17_1)\nconv_17_1_do = Dropout(droprate)(conv_17_1_bn)\n\nconv_17_2 = SeparableConv2D(filters = 128, kernel_size = 3, activation='relu', padding='same')(conv_17_1_do)\nconv_17_2_bn = BatchNormalization()(conv_17_2)\nconv_17_2_do = Dropout(droprate)(conv_17_2_bn)\n\nupconv_8 = upconv_concat(conv_17_2_do, conv_10_2_do, n_filter=64, pool_size=2, stride=2)  #Module 17 to 18\n\n#Module 18\n\nconv_18_1 = Conv2D(filters = 64, kernel_size = 3, activation='relu', padding='same')(upconv_8)\nconv_18_1_bn = BatchNormalization()(conv_18_1)\nconv_18_1_do = Dropout(droprate)(conv_18_1_bn)\n\nconv_18_2 = Conv2D(filters = 64, kernel_size = 3, activation='relu', padding='same')(conv_18_1_do)\nconv_18_2_bn = BatchNormalization()(conv_18_2)\nconv_18_2_do = Dropout(droprate)(conv_18_2_bn)\n\ndecoder_output =  Conv2D(filters = 1, kernel_size = 1, activation='relu', padding='same')(conv_18_2_do)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encoder Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_model = Model(input_img, encoder_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#parameters for normalized cut loss\nsigma_pixel = tf.square(tf.constant(10.0))\nsigma_dist = 4.0 ** 2\nr = 5 #radius\nk = tf.constant(num_classes, dtype=tf.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#place holders for encoder model\noriginal_image = tf.placeholder(dtype=tf.float32, shape=[None, 224, 224, 1]) #same as input image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalized cut loss and optimizer for encoder model\n\n\n#create a spatial kernel\n\ns = 2 * r + 1\nspatial_kernel = np.zeros((s, s), dtype=np.float32)\nfor y in range(s):\n    for x in range(s):\n        # calculate squared euclidean distance\n        dist = (x - r) * (x - r) + (y - r) * (y - r)\n        if dist < (r * r):\n            spatial_kernel[y][x] = np.exp((-dist) / sigma_dist)\n\nspatial_kernel = tf.constant(spatial_kernel.reshape(-1), dtype=tf.float32)\n\n\n#create one dimensional kernel\n\ns = 2 * r + 1\none_dim_kernel = np.zeros((s, s, (s * s)))\nfor i in range(s * s):\n    one_dim_kernel[int(i / s)][i % s][i] = 1.0\none_dim_kernel = one_dim_kernel.reshape(s, s, 1, (s * s))\none_dim_kernel = tf.constant(one_dim_kernel, dtype=tf.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class calc_norm_loss():\n    def __init__(self):\n        self.num_sum = tf.constant(0.0, dtype=tf.float32)\n    def cal_sum(self):\n        for depth in range(num_classes):\n            softmax_layer = encoder_model(original_image)[:, :, :, depth:depth + 1]\n            extracted_pixels = tf.nn.conv2d(softmax_layer, one_dim_kernel, strides=[1, 1, 1, 1], padding='SAME')\n\n            intensity_sq_dif = tf.squared_difference(extracted_pixels, softmax_layer)\n            intensity_values = tf.exp(tf.divide(tf.negative(intensity_sq_dif), sigma_pixel))\n\n            weights = tf.multiply(intensity_values, spatial_kernel)\n            # Reshape Input Softmax Layer for correct dimensions\n            u_pixels = tf.reshape(softmax_layer, [batch_size, 224, 224])\n            # Calculate entire numerator\n            numerator_inner_sum = tf.reduce_sum(tf.multiply(weights, extracted_pixels), axis=3)\n            numerator_outer_sum = tf.multiply(u_pixels, numerator_inner_sum)\n            numerator = tf.reduce_sum(numerator_outer_sum)\n            # Calculate denominator\n            denominator_inner_sum = tf.reduce_sum(weights, axis=3)\n            denominator_outer_sum = tf.multiply(u_pixels, denominator_inner_sum)\n            denominator = tf.reduce_sum(denominator_outer_sum)\n\n            processed_value = numerator / denominator\n            self.num_sum += processed_value\n            print(\"came here\")\n            return self.num_sum","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"norm_loss = calc_norm_loss()\nnorm_cut_loss = k-norm_loss.cal_sum()\nnorm_cut_opt = tf.train.AdamOptimizer(learning_rate=enc_lr, beta1=0.9, beta2=0.999).minimize(norm_cut_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"init1 = tf.global_variables_initializer()\ninit2 = tf.local_variables_initializer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train encoder model\nwith tf.Session() as sess:\n    sess.run(init1)\n    sess.run(init2)\n    for epoch in range(num_epochs):\n        print(\"epoch:\", epoch)\n        count = 0\n        batch_start_index = 0\n        while (count != num_batches):\n            X_train_batch = X_train[batch_start_index : batch_start_index+batch_size]\n            _, train_loss = sess.run([norm_cut_opt,norm_cut_loss], feed_dict={original_image: X_train_batch})\n            batch_start_index+=batch_size\n            count+=1\n        print(\"Train loss after \", str(epoch), \"is\", str(train_loss))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Full model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# wnet_autoencoder = Model(input_img, decoder_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# wnet_autoencoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #place holders for wnet_autoencoder\n# input_image = tf.placeholder(dtype=tf.float32, shape=[None, 224, 224, 1])\n\n# # Reconstruction loss and loss for autoencoder model\n# rec_loss = tf.reduce_mean(tf.squared_difference(wnet_autoencoder(input_image), input_image))\n# rec_opt = tf.train.GradientDescentOptimizer(learning_rate=ae_lr).minimize(rec_loss)\n\n# init1 = tf.global_variables_initializer()\n# init2 = tf.local_variables_initializer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #train autoencoder\n# with tf.Session() as sess:\n#     sess.run(init1)\n#     sess.run(init2)\n#     for epoch in range(num_epochs):\n#         print(\"epoch:\", epoch)\n#         count = 0\n#         batch_start_index = 0\n#         while (count != num_batches):\n#             X_train_batch = X_train[batch_start_index : batch_start_index+batch_size]\n#             _, train_loss = sess.run([rec_opt,rec_loss], feed_dict={input_image: X_train_batch})\n#             batch_start_index+=batch_size\n#             count+=1\n#         print(\"Train loss after \", str(epoch), \"is\", str(train_loss))\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train full Auto-Encoder with keras\n\n# with tf.Session() as sess:\n#     sess.run(init1)\n#     sess.run(init2)\n#     wnet_autoencoder.compile(optimizer='adagrad', loss='mean_squared_error')\n#     history = wnet_autoencoder.fit(X_train, X_train,\n#                     epochs=5,\n#                     batch_size=8,\n#                     shuffle=True,\n#                     validation_data=(X_val, X_val)).history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train Encoder with keras. \n\n# with tf.Session() as sess:\n#     sess.run(init1)\n#     sess.run(init2)\n#     encoder_model.compile(optimizer='adagrad', loss='sparse_categorical_crossentropy')\n#     history = encoder_model.fit(X_train, X_train,\n#                     epochs=5,\n#                     batch_size=8,\n#                     shuffle=True,\n#                     validation_data=(X_val, X_val)).history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot graph for train_loss vs val_loss for keras training\n\n# plt.plot(history['loss'], linewidth=2, label='Train')\n# plt.plot(history['val_loss'], linewidth=2, label='Test')\n# plt.legend(loc='upper right')\n# plt.title('Model loss')\n# plt.ylabel('Loss')\n# plt.xlabel('Epoch')\n# # plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing the Resutls"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load a test image and preprocess it.\n\nimg = cv2.imread('../input/test-dataset/a184.jpg')\nimg = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\nresized = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA)\nresized = resized/255\nresized1 = resized[:, :, np.newaxis]\nprint(resized1.shape)\nresized1 = resized1[np.newaxis, :, :] \nprint(resized1.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"init1 = tf.global_variables_initializer()\ninit2 = tf.local_variables_initializer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test Encoder model\nwith tf.Session() as sess:\n    sess.run(init1)\n    sess.run(init2)\n    img3 = encoder_model.predict(resized1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(img3.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img3 = np.reshape(img3, (224,224,3))\nplt.imshow(img3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img3[0][0][0] + img3[0][0][1] + img3[0][0][2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_image_copy = img3.copy()\n\noutput_image_copy[:, :, 2] = 0\noutput_image_copy[:, :, 0] = 0\n\n#output_image_copy = output_image_copy*255\nplt.imshow(output_image_copy)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}