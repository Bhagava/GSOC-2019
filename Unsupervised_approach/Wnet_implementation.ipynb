{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy.random import seed\nseed(1)\nfrom tensorflow import set_random_seed\nset_random_seed(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip freeze","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv2D, SeparableConv2D, Conv2DTranspose\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Concatenate\nfrom tensorflow.keras.layers import Lambda\nfrom tensorflow.keras.models import Model\n\nimport os\nimport cv2\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def upconv_concat(bottom_a, bottom_b, n_filter, pool_size, stride, padding='VALID'):\n    up_conv = Conv2DTranspose(filters=n_filter, kernel_size=[pool_size, pool_size],\n                                         strides=stride, padding=padding)(bottom_a)\n    return Concatenate(axis=-1)([up_conv, bottom_b])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip show tensorflow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pre-process images\n\ntrain_images = os.listdir('../input/wnetdataset/data/Data/train')\nval_images = os.listdir('../input/wnetdataset/data/Data/val')\n\nX_train = []\nX_val = []\n\nfor i in range(len(train_images)):\n    img = cv2.imread('../input/wnetdataset/data/Data/train/'+train_images[i])\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    resized = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA)\n    resized = resized/255\n    resized = resized[:, :, np.newaxis]\n    X_train.append(resized)\nX_train = np.asarray(X_train)\n\nfor i in range(len(val_images)):\n    img = cv2.imread('../input/wnetdataset/data/Data/val/'+val_images[i])\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    resized = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA)\n    resized = resized/255\n    resized = resized[:, :, np.newaxis]\n    X_val.append(resized)\nX_val = np.asarray(X_val)\n    \n    \nprint(len(X_train))\nprint(len(X_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import os\n# import cv2\n# import matplotlib.pyplot as plt\n\n# train_path = '../input/wnet-data-large/data_large/Data_Large/train/'\n# val_path = '../input/wnet-data-large/data_large/Data_Large/val/'\n\n# train_images = os.listdir(train_path)\n# val_images = os.listdir(val_path)\n\n# X_train = []\n# X_val = []\n\n# # Prepare X_train\n\n# for i in range(len(train_images)):\n#     img = cv2.imread(train_path+train_images[i]) #read all images\n#     img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # Convert images to Grayscale\n#     resized = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA) #Resize image to (224, 224)\n#     X_train.append(resized) # append to list\n    \n# X_train = np.asarray(X_train) #convert to numpy array\n# X_train = X_train.astype('float32')/255. # Standardizing the data\n# X_train = np.reshape(X_train, (len(X_train), 224, 224, 1)) #reshape it to (1140, 224, 224, 1) for feeding to model\n\n# #Prepare X_val\n\n# for i in range(len(val_images)):\n#     img = cv2.imread(val_path+val_images[i]) #read all images\n#     img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)  # Convert images to Grayscale\n#     resized = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA) #Resize image to (224, 224)\n#     X_val.append(resized) # append to list\n    \n# X_val = np.asarray(X_val) #convert to numpy array\n# X_val = X_val.astype('float32')/255. # Standardizing the data\n# X_val = np.reshape(X_val, (len(X_val), 224, 224, 1)) #reshape it to (100, 224, 224, 1) fro feeding to model\n\n# print(\"Number of train images:\",len(X_train), \"Shape of X_train:\", X_train.shape)\n# print(\"Number of val images:\",len(X_val), \"Shape of X_val:\", X_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Custom_Conv2(tf.keras.layers.Layer):\n    def __init__(self, *args, **kargs):\n        super(Custom_Conv2, self).__init__()\n    def call(self, bottom, k_size, num_outputs, stride):\n        input_channels = int(bottom.get_shape()[-1])\n\n        # initialize weights and biases using xavier\n        weights = tf.Variable(tf.truncated_normal(shape=[k_size, k_size, input_channels, num_outputs], dtype=tf.float32, stddev=np.sqrt(1.0 / (k_size * k_size * input_channels))))\n\n        biases = tf.Variable(tf.constant(0, dtype=tf.float32, shape=[num_outputs]))\n        \n        # conv = convolve(bottom, weights)\n        conv = tf.nn.conv2d(bottom, weights, strides=[1, stride, stride, 1], padding='SAME')\n\n        # Add biases\n        bias = tf.reshape(tf.nn.bias_add(conv, biases), tf.shape(conv))\n\n        # Apply relu function\n        relu = tf.nn.relu(bias)\n        return relu","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Custom_Conv(bottom):\n    input_channels = int(bottom.get_shape()[-1])\n\n    # initialize weights and biases using xavier\n    weights = tf.Variable(tf.truncated_normal(shape=[1, 1, input_channels, 3], dtype=tf.float32, stddev=tf.sqrt(1.0 / (1 * 1 * input_channels))))\n\n    biases = tf.Variable(tf.constant(0, dtype=tf.float32, shape=[3]))\n\n    # conv = convolve(bottom, weights)\n    conv = tf.nn.conv2d(bottom, weights, strides=[1, 1, 1, 1], padding='SAME')\n\n    # Add biases\n    bias = tf.reshape(tf.nn.bias_add(conv, biases), tf.shape(conv))\n\n    # Apply relu function\n    relu = tf.nn.relu(bias)\n    return relu","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_img = Input(shape=(224, 224, 1))\ndroprate=0.25\nnum_classes = 3 #background, cell boundary, cell.","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Encoder\n\n#Module 1\nconv_1_1 = Conv2D(filters = 64, kernel_size = 3, activation='relu', padding='same')(input_img)\nconv_1_1_bn = BatchNormalization()(conv_1_1)\nconv_1_1_do = Dropout(droprate)(conv_1_1_bn)\n\nconv_1_2 = Conv2D(filters = 64, kernel_size = 3, activation='relu', padding='same')(conv_1_1_do)\nconv_1_2_bn = BatchNormalization()(conv_1_2)\nconv_1_2_do = Dropout(droprate)(conv_1_2_bn)\n\npool_1 = MaxPooling2D(pool_size= 2, strides = 2)(conv_1_2_do) #Module 1 to Module 2\n\n#Module 2\n\nconv_2_1 = SeparableConv2D(filters = 128, kernel_size = 3, activation='relu', padding='same')(pool_1)\nconv_2_1_bn = BatchNormalization()(conv_2_1)\nconv_2_1_do = Dropout(droprate)(conv_2_1_bn)\n\nconv_2_2 = SeparableConv2D(filters = 128, kernel_size = 3, activation='relu', padding='same')(conv_2_1_do)\nconv_2_2_bn = BatchNormalization()(conv_2_2)\nconv_2_2_do = Dropout(droprate)(conv_2_2_bn)\n\npool_2 = MaxPooling2D(pool_size= 2, strides = 2)(conv_2_2_do) #Module 2 to Module 3\n\n#Module 3\n\nconv_3_1 = SeparableConv2D(filters = 256, kernel_size = 3, activation='relu', padding='same')(pool_2)\nconv_3_1_bn = BatchNormalization()(conv_3_1)\nconv_3_1_do = Dropout(droprate)(conv_3_1_bn)\n\nconv_3_2 = SeparableConv2D(filters = 256, kernel_size = 3, activation='relu', padding='same')(conv_3_1_do)\nconv_3_2_bn = BatchNormalization()(conv_3_2)\nconv_3_2_do = Dropout(droprate)(conv_3_2_bn)\n\npool_3 = MaxPooling2D(pool_size= 2, strides = 2)(conv_3_2_do) #Module 3 to Module 4\n\n#Module 4\n\nconv_4_1 = SeparableConv2D(filters = 512, kernel_size = 3, activation='relu', padding='same')(pool_3)\nconv_4_1_bn = BatchNormalization()(conv_4_1)\nconv_4_1_do = Dropout(droprate)(conv_4_1_bn)\n\nconv_4_2 = SeparableConv2D(filters = 512, kernel_size = 3, activation='relu', padding='same')(conv_4_1_do)\nconv_4_2_bn = BatchNormalization()(conv_4_2)\nconv_4_2_do = Dropout(droprate)(conv_4_2_bn)\n\npool_4 = MaxPooling2D(pool_size= 2, strides = 2)(conv_4_2_do) #Module 4 to Module 5\n\n#Module 5\n\nconv_5_1 = SeparableConv2D(filters = 1024, kernel_size = 3, activation='relu', padding='same')(pool_4)\nconv_5_1_bn = BatchNormalization()(conv_5_1)\nconv_5_1_do = Dropout(droprate)(conv_5_1_bn)\n\nconv_5_2 = SeparableConv2D(filters = 1024, kernel_size = 3, activation='relu', padding='same')(conv_5_1_do)\nconv_5_2_bn = BatchNormalization()(conv_5_2)\nconv_5_2_do = Dropout(droprate)(conv_5_2_bn)\n\nupconv_1 = upconv_concat(conv_5_2_do, conv_4_2_do, n_filter=512, pool_size=2, stride=2) #Module 5 to 6\n\n#Module 6\n\nconv_6_1 = SeparableConv2D(filters = 512, kernel_size = 3, activation='relu', padding='same')(upconv_1)\nconv_6_1_bn = BatchNormalization()(conv_6_1)\nconv_6_1_do = Dropout(droprate)(conv_6_1_bn)\n\nconv_6_2 = SeparableConv2D(filters = 512, kernel_size = 3, activation='relu', padding='same')(conv_6_1_do)\nconv_6_2_bn = BatchNormalization()(conv_6_2)\nconv_6_2_do = Dropout(droprate)(conv_6_2_bn)\n\nupconv_2 = upconv_concat(conv_6_2_do, conv_3_2_do, n_filter=256, pool_size=2, stride=2) #Module 6 to 7\n\n#Module 7\n\nconv_7_1 = SeparableConv2D(filters = 256, kernel_size = 3, activation='relu', padding='same')(upconv_2)\nconv_7_1_bn = BatchNormalization()(conv_7_1)\nconv_7_1_do = Dropout(droprate)(conv_7_1_bn)\n\nconv_7_2 = SeparableConv2D(filters = 256, kernel_size = 3, activation='relu', padding='same')(conv_7_1_do)\nconv_7_2_bn = BatchNormalization()(conv_7_2)\nconv_7_2_do = Dropout(droprate)(conv_7_2_bn)\n\nupconv_3 = upconv_concat(conv_7_2_do, conv_2_2_do, n_filter=128, pool_size=2, stride=2) #Module 7 to 8\n\n#Module 8\n\nconv_8_1 = SeparableConv2D(filters = 128, kernel_size = 3, activation='relu', padding='same')(upconv_3)\nconv_8_1_bn = BatchNormalization()(conv_8_1)\nconv_8_1_do = Dropout(droprate)(conv_8_1_bn)\n\nconv_8_2 = SeparableConv2D(filters = 128, kernel_size = 3, activation='relu', padding='same')(conv_8_1_do)\nconv_8_2_bn = BatchNormalization()(conv_8_2)\nconv_8_2_do = Dropout(droprate)(conv_8_2_bn)\n\nupconv_4 = upconv_concat(conv_8_2_do, conv_1_2_do, n_filter=64, pool_size=2, stride=2) #Module 8 to 9\n\n#Module 9\n\nconv_9_1 = SeparableConv2D(filters = 64, kernel_size = 3, activation='relu', padding='same')(upconv_4)\nconv_9_1_bn = BatchNormalization()(conv_9_1)\nconv_9_1_do = Dropout(droprate)(conv_9_1_bn)\n\nconv_9_2 = SeparableConv2D(filters = 64, kernel_size = 3, activation='relu', padding='same')(conv_9_1_do)\nconv_9_2_bn = BatchNormalization()(conv_9_2)\nconv_9_2_do = Dropout(droprate)(conv_9_2_bn)\n\nencoder_output = Lambda(Custom_Conv)(conv_9_2_do) #Module 9 to 10\n# encoder_output = Custom_Conv2()(conv_9_2_do, k_size=1, num_outputs=3, stride=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Decoder\n\n# #Module 10\n\n# conv_10_1 = Conv2D(filters = 64, kernel_size = 3, activation='relu', padding='same')(encoder_output)\n# conv_10_1_bn = BatchNormalization()(conv_10_1)\n# conv_10_1_do = Dropout(droprate)(conv_10_1_bn)\n\n# conv_10_2 = Conv2D(filters = 64, kernel_size = 3, activation='relu', padding='same')(conv_10_1_do)\n# conv_10_2_bn = BatchNormalization()(conv_10_2)\n# conv_10_2_do = Dropout(droprate)(conv_10_2_bn)\n\n# pool_5 = MaxPooling2D(pool_size= 2, strides = 2)(conv_10_2_do) #Module 10 to 11\n\n# #Module 11\n\n# conv_11_1 = SeparableConv2D(filters = 128, kernel_size = 3, activation='relu', padding='same')(pool_5)\n# conv_11_1_bn = BatchNormalization()(conv_11_1)\n# conv_11_1_do = Dropout(droprate)(conv_11_1_bn)\n\n# conv_11_2 = SeparableConv2D(filters = 128, kernel_size = 3, activation='relu', padding='same')(conv_11_1_do)\n# conv_11_2_bn = BatchNormalization()(conv_11_2)\n# conv_11_2_do = Dropout(droprate)(conv_11_2_bn)\n\n# pool_6 = MaxPooling2D(pool_size= 2, strides = 2)(conv_11_2_do) #Module 11 to 12\n\n# #Module 12\n\n# conv_12_1 = SeparableConv2D(filters = 256, kernel_size = 3, activation='relu', padding='same')(pool_6)\n# conv_12_1_bn = BatchNormalization()(conv_12_1)\n# conv_12_1_do = Dropout(droprate)(conv_12_1_bn)\n\n# conv_12_2 = SeparableConv2D(filters = 256, kernel_size = 3, activation='relu', padding='same')(conv_12_1_do)\n# conv_12_2_bn = BatchNormalization()(conv_12_2)\n# conv_12_2_do = Dropout(droprate)(conv_12_2_bn)\n\n# pool_7 = MaxPooling2D(pool_size= 2, strides = 2)(conv_12_2_do) #Module 12 to 13\n\n# #Module 13\n\n# conv_13_1 = SeparableConv2D(filters = 512, kernel_size = 3, activation='relu', padding='same')(pool_7)\n# conv_13_1_bn = BatchNormalization()(conv_13_1)\n# conv_13_1_do = Dropout(droprate)(conv_13_1_bn)\n\n# conv_13_2 = SeparableConv2D(filters = 512, kernel_size = 3, activation='relu', padding='same')(conv_13_1_do)\n# conv_13_2_bn = BatchNormalization()(conv_13_2)\n# conv_13_2_do = Dropout(droprate)(conv_13_2_bn)\n\n# pool_8 = MaxPooling2D(pool_size= 2, strides = 2)(conv_13_2_do) #Module 13 to 14\n\n# #Module 14\n\n# conv_14_1 = SeparableConv2D(filters = 1024, kernel_size = 3, activation='relu', padding='same')(pool_8)\n# conv_14_1_bn = BatchNormalization()(conv_14_1)\n# conv_14_1_do = Dropout(droprate)(conv_14_1_bn)\n\n# conv_14_2 = SeparableConv2D(filters = 1024, kernel_size = 3, activation='relu', padding='same')(conv_14_1_do)\n# conv_14_2_bn = BatchNormalization()(conv_14_2)\n# conv_14_2_do = Dropout(droprate)(conv_14_2_bn)\n\n# upconv_5 = upconv_concat(conv_14_2_do, conv_13_2_do, n_filter=512, pool_size=2, stride=2)  #Module 14 to 15\n\n# #Module 15\n\n# conv_15_1 = SeparableConv2D(filters = 512, kernel_size = 3, activation='relu', padding='same')(upconv_5)\n# conv_15_1_bn = BatchNormalization()(conv_15_1)\n# conv_15_1_do = Dropout(droprate)(conv_15_1_bn)\n\n# conv_15_2 = SeparableConv2D(filters = 512, kernel_size = 3, activation='relu', padding='same')(conv_15_1_do)\n# conv_15_2_bn = BatchNormalization()(conv_15_2)\n# conv_15_2_do = Dropout(droprate)(conv_15_2_bn)\n\n# upconv_6 = upconv_concat(conv_15_2_do, conv_12_2_do, n_filter=256, pool_size=2, stride=2)  #Module 15 to 16\n\n# #Module 16\n\n# conv_16_1 = SeparableConv2D(filters = 256, kernel_size = 3, activation='relu', padding='same')(upconv_6)\n# conv_16_1_bn = BatchNormalization()(conv_16_1)\n# conv_16_1_do = Dropout(droprate)(conv_16_1_bn)\n\n# conv_16_2 = SeparableConv2D(filters = 256, kernel_size = 3, activation='relu', padding='same')(conv_16_1_do)\n# conv_16_2_bn = BatchNormalization()(conv_16_2)\n# conv_16_2_do = Dropout(droprate)(conv_16_2_bn)\n\n# upconv_7 = upconv_concat(conv_16_2_do, conv_11_2_do, n_filter=128, pool_size=2, stride=2)  #Module 16 to 17\n\n# #Module 17\n\n# conv_17_1 = SeparableConv2D(filters = 128, kernel_size = 3, activation='relu', padding='same')(upconv_7)\n# conv_17_1_bn = BatchNormalization()(conv_17_1)\n# conv_17_1_do = Dropout(droprate)(conv_17_1_bn)\n\n# conv_17_2 = SeparableConv2D(filters = 128, kernel_size = 3, activation='relu', padding='same')(conv_17_1_do)\n# conv_17_2_bn = BatchNormalization()(conv_17_2)\n# conv_17_2_do = Dropout(droprate)(conv_17_2_bn)\n\n# upconv_8 = upconv_concat(conv_17_2_do, conv_10_2_do, n_filter=64, pool_size=2, stride=2)  #Module 17 to 18\n\n# #Module 18\n\n# conv_18_1 = Conv2D(filters = 64, kernel_size = 3, activation='relu', padding='same')(upconv_8)\n# conv_18_1_bn = BatchNormalization()(conv_18_1)\n# conv_18_1_do = Dropout(droprate)(conv_18_1_bn)\n\n# conv_18_2 = Conv2D(filters = 64, kernel_size = 3, activation='relu', padding='same')(conv_18_1_do)\n# conv_18_2_bn = BatchNormalization()(conv_18_2)\n# conv_18_2_do = Dropout(droprate)(conv_18_2_bn)\n\n# decoder_output = Custom_Conv2()(conv_18_2_do, k_size=1, num_outputs=1, stride=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_model = Model(input_img, encoder_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"init1 = tf.global_variables_initializer()\ninit2 = tf.local_variables_initializer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.Session() as sess:\n    sess.run(init1)\n    encoder_model.compile(optimizer='adagrad', loss='mean_squared_error')\n    history = encoder_model.fit(X_train, X_train,\n            epochs=5,\n            batch_size=8,\n            shuffle=False,\n            validation_data=(X_val, X_val)).history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"init1 = tf.global_variables_initializer()\ninit2 = tf.local_variables_initializer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.Session() as sess:\n    sess.run(init1)\n    encoder_model.save(\"encoder_model_5_lambda_withth.h5\")\n    json_string = encoder_model.to_json()\n    encoder_model.save_weights('encoder_model_5_weights_lambda_withtf.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle as serializer\n\nwith open('model_json_lambda_withtf.txt', 'w') as f:\n    f.write(str(json_string))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history['loss'], linewidth=2, label='Train')\nplt.plot(history['val_loss'], linewidth=2, label='Test')\nplt.legend(loc='upper right')\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\n#plt.ylim(ymin=0.70,ymax=1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import load_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_model =load_model('../input/lambda-tf-model/encoder_model_5_lambda_withth.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = cv2.imread('../input/test-dataset/a184.jpg')\nimg = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\nresized = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA)\nresized = resized/255\nresized1 = resized[:, :, np.newaxis]\nprint(resized1.shape)\nresized1 = resized1[np.newaxis, :, :] \nprint(resized1.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"init1 = tf.global_variables_initializer()\ninit2 = tf.local_variables_initializer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.Session() as sess:\n    sess.run(init1)\n    img4 = encoder_model.predict(resized1)\nimg4.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img4 = img4*255.\n# img4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(img4.reshape(224,224,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_resized = img4.reshape(224,224,3).copy()\nimg_resized = img_resized[:, :, 2]\nimg_resized = img_resized\nplt.imshow(img_resized)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# img_resized = img4.reshape(224,224,3).copy()\n# img_resized[:, :, 0]= 0\n# img_resized[:, :, 2]= 0\n# img_resized = img_resized * 10\n# plt.imshow(img_resized)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}